# Chapter 1: Introduction 引言
# 本章介绍机器学习的基本概念，通过多项式曲线拟合的例子展示关键概念

name: "Introduction"

# 1.1 多项式曲线拟合示例配置
polynomial_fitting:
  # 生成训练数据的参数
  data_generation:
    n_train: 10  # 训练样本数量
    n_test: 100  # 测试样本数量  
    noise_std: 0.3  # 高斯噪声标准差
    x_min: 0  # x的最小值
    x_max: 1  # x的最大值
    true_function: "sin"  # 真实函数: sin(2*pi*x)
    
  # 多项式阶数配置
  polynomial_orders: [0, 1, 3, 9]  # 要测试的多项式阶数
  
  # 正则化参数配置
  regularization:
    enabled: true
    lambda_values: [0, 1e-18, 1e-4, 1]  # 正则化系数λ的值
    
# 1.2 概率论回顾配置
probability_theory:
  # 贝叶斯定理演示
  bayes_example:
    prior_prob: 0.01  # 先验概率
    likelihood: 0.99  # 似然度
    false_positive_rate: 0.05  # 假阳性率
    
  # 概率分布可视化
  distributions:
    gaussian:
      mean: 0
      std: 1
      n_samples: 1000
    binomial:
      n: 10
      p: 0.3
      n_samples: 1000
      
# 1.3 模型选择配置
model_selection:
  # 交叉验证配置
  cross_validation:
    n_folds: 5  # k折交叉验证的k值
    polynomial_orders: [1, 2, 3, 4, 5, 6, 7, 8, 9]
    
# 1.4 维度诅咒演示配置  
curse_of_dimensionality:
  dimensions: [1, 2, 3, 5, 10, 20, 50, 100]  # 要测试的维度
  n_samples: 1000  # 每个维度的样本数
  
# 1.5 决策论配置
decision_theory:
  # 分类决策边界演示
  classification:
    n_classes: 3
    n_samples_per_class: 100
    
  # 回归损失函数比较
  loss_functions: ["squared", "absolute", "huber"]
  
# 1.6 信息论配置
information_theory:
  # 熵的计算和可视化
  entropy_demo:
    n_bins: 20
    distributions: ["uniform", "gaussian", "exponential"]